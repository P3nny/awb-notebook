{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWB (Anwendungsbeobachtungen, Observational Studies)\n",
    "\n",
    "This notebook reads in and cleans the received AWB data and shows some basic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import glob\n",
    "from datetime import datetime, date, timedelta\n",
    "import os\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame, Series\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['svg.fonttype'] = 'none'\n",
    "\n",
    "pd.options.display.max_rows = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = [('data/AWB KBV Meldungen und Abschlüsse 2004 - 2011.xlsx', range(2009, 2012)),\n",
    "             ('data/AWB KBV Meldungen und Abschlüsse 2012 - 2014.xlsx', (2012, 2013, 2014))]\n",
    "\n",
    "\n",
    "def read_excel(filename, years, kind='update', needle='Meldungen'):\n",
    "    xl_file = pd.ExcelFile(filename)\n",
    "    sheet_names = xl_file.sheet_names\n",
    "\n",
    "    for year in years:\n",
    "        sheet_name = [x for x in sheet_names if str(year) in x and needle in x][0]\n",
    "        print(filename, sheet_name)\n",
    "        df = xl_file.parse(sheet_name)\n",
    "        # Make index into row number column\n",
    "        df = df.reset_index()\n",
    "        df['year'] = year\n",
    "        df['row_type'] = kind\n",
    "        df = df.rename(columns=dict([(x, x.strip()) for x in df.columns if x.strip() != x]))\n",
    "        # Consolidate column names \n",
    "        df = df.rename(columns={u'Präparat': u'Präparatname',\n",
    "                                u'Präparat/Titel der Anwendung': u'Präparatname',\n",
    "                                u'gemeldet am': 'DatumErstanzeige',\n",
    "                                u'Datum Erstanzeige': 'DatumErstanzeige',\n",
    "                                u'Beobachtugsplan vorliegend': 'Beobachtungsplan vorliegend',\n",
    "                                u'Ärzte gemeldet': u'gemeldete Ärzte',\n",
    "                                u'Anzahl teilnehmende Ärzte (wenn angegeben)': u'gemeldete Ärzte',\n",
    "                                u'Anzahl der beobachtenden Ärzte': u'beobachtende Ärzte',\n",
    "                                'index': 'row_number'\n",
    "                               })\n",
    "        if 'DatumErstanzeige' not in df.columns:\n",
    "            df = df.rename(columns={'Eingang': 'DatumErstanzeige'})\n",
    "        # Fix date columns\n",
    "        date_cols = list(df.columns[df.columns.str.startswith('Datum')])\n",
    "        for x in date_cols:\n",
    "            df['dt_%s' % x] = pd.to_datetime(df[x], errors='coerce')\n",
    "        df[u'Präparatname'] = df[u'Präparatname'].str.strip()\n",
    "        # Remove entries with empty drug name\n",
    "        df = df[df[u'Präparatname'].notnull()]\n",
    "        yield df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, read in all available update messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_cols = ['Patienten geplant', 'Patienten beobachtet', u'gemeldete Ärzte', u'beobachtende Ärzte',\n",
    "            u'Vertragsärzte', u'Aufwandsentschädigung pro Patient']\n",
    "float_cols = [u'Aufwandsentschädigung pro Patient']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/AWB KBV Meldungen und Abschlüsse 2004 - 2011.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a83e3e70162d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_updates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# To be compatible with Abschluesse column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_updates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Aufwandsentschädigung gesamt in €'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ddj/v/lib/python3.5/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, join_axes, ignore_index, keys, levels, names, verify_integrity, copy)\u001b[0m\n\u001b[1;32m    204\u001b[0m                        \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                        \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                        copy=copy)\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ddj/v/lib/python3.5/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, join_axes, keys, levels, names, ignore_index, verify_integrity, copy)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mobjs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0mobjs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-deda6c35b421>\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(filename, years, kind, needle)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myears\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'update'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneedle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Meldungen'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mxl_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0msheet_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxl_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msheet_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ddj/v/lib/python3.5/site-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, io, **kwds)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[0;32m~/ddj/v/lib/python3.5/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# a ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/AWB KBV Meldungen und Abschlüsse 2004 - 2011.xlsx'"
     ]
    }
   ],
   "source": [
    "df_updates = pd.concat(itertools.chain(*[read_excel(*args) for args in filenames]))\n",
    "\n",
    "# To be compatible with Abschluesse column\n",
    "df_updates['Aufwandsentschädigung gesamt in €'] = None\n",
    "\n",
    "print('Number of rows', len(df_updates))\n",
    "df_updates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catch bogus row that is way down and contains a different header\n",
    "# Interesting colum \"HonorarPlausibilität\" (plausibility of fee) which is not available in our dataset\n",
    "bad_series = df_updates[df_updates['Art der NIS'] == 'Art der NIS'].T.iloc[:,0]\n",
    "# Remove the row before processing further\n",
    "df_updates = df_updates[~(df_updates['Art der NIS'] == 'Art der NIS')]\n",
    "bad_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in all final notices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abschluesse_df = pd.concat(itertools.chain(*[read_excel(*args, needle='Abschl', kind='final') for args in filenames]))\n",
    "\n",
    "abschluesse_df\n",
    "\n",
    "# Make columns compatible with update notices\n",
    "columns = u'dt_DatumErstanzeige\tdt_DatumStart\tdt_DatumEingang\tPräparatname\tWirkstoff\tFirma\tPatienten beobachtet\tPatienten geplant\tbeobachtende Ärzte\tgemeldete Ärzte\tAufwandsentschädigung pro Patient\tAufwandsentschädigung Kommentar\tAufwandsentschädigung gesamt in €\tArt der NIS\tAuftraggeber\tBeobachtungsplan vorliegend\tBeobachtungszeitraumKommentar\tBrief/Mail/Fax\tDatumAbmeldung\tDatumBrief\tDatumEingang\tDatumEnde\tKommentar\tMeldungsGrund\tMeldungsKommentar\tMeldungsart\tMeldungsinhalt\tTitel (Ziel)\tTyp\tVertrag vorliegend\tVertragsärzte\tdt_DatumAbmeldung\tdt_DatumBrief\tdt_DatumEnde\tyear'.split('\\t')\n",
    "for c in columns:\n",
    "    if c not in abschluesse_df:\n",
    "        abschluesse_df[c] = None\n",
    "\n",
    "print('Number of rows', len(abschluesse_df))\n",
    "abschluesse_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as before, remove bogus header row at line 12607 of final notices in year 2013\n",
    "bad_series = abschluesse_df[abschluesse_df['Art der NIS'] == 'Art der NIS'].T.iloc[:,0]\n",
    "# Remove the row before processing further\n",
    "abschluesse_df = abschluesse_df[~(abschluesse_df['Art der NIS'] == 'Art der NIS')]\n",
    "bad_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get cleaner number representation of total amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numbers\n",
    "\n",
    "NUMBER_RE = re.compile('^\\s*([\\d\\., ]+)')\n",
    "NUMBERS_RE = {\n",
    "    re.compile(r'^([\\d\\.]+),(\\d{1,2}]+)'): '.',\n",
    "    re.compile(r'^([\\d,]+)\\.(\\d{1,2}]+)'): ',',\n",
    "}\n",
    "\n",
    "def clean_money(x):\n",
    "    if isinstance(x, numbers.Number):\n",
    "        return x\n",
    "    x = NUMBER_RE.sub('\\\\1', x)\n",
    "    for reg, repl in NUMBERS_RE.items():\n",
    "        m = reg.search(x)\n",
    "        if m is None:\n",
    "            continue\n",
    "        before = int(m.group(1).replace(repl, ''))\n",
    "        after = int(m.group(2))\n",
    "        if after < 10:\n",
    "            after = after / 10.0\n",
    "        else:\n",
    "            after = after / 100.0\n",
    "        return before + after\n",
    "    return None\n",
    "    \n",
    "abschluesse_df['Aufwandsentschädigung gesamt'] = abschluesse_df['Aufwandsentschädigung gesamt in €'].apply(clean_money)\n",
    "abschluesse_df[['Aufwandsentschädigung gesamt', 'Aufwandsentschädigung gesamt in €']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouper = ['dt_DatumErstanzeige', 'dt_DatumStart']\n",
    "\n",
    "# Fill missing values in grouping columns with dummy value,\n",
    "# so it's not silently dropped by pandas groupby\n",
    "dummy_date = pd.to_datetime(date(1900, 1, 1))\n",
    "abschluesse_df[grouper] = abschluesse_df[grouper].fillna(dummy_date)\n",
    "df_updates[grouper] = df_updates[grouper].fillna(dummy_date)\n",
    "\n",
    "assert not abschluesse_df[grouper].isnull().any().any()\n",
    "assert not df_updates[grouper].isnull().any().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine update notices and final notices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_updates, abschluesse_df])\n",
    "df_all = df_all.reset_index(drop=True)\n",
    "\n",
    "df_all['row_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add simpler version of präparatname that might group better later\n",
    "\n",
    "DRUG_NAME_SPLITTER = re.compile(r'[^\\w ]|\\d|_', re.U | re.I)\n",
    "\n",
    "def clean_praeparat(praeparat):\n",
    "    name = DRUG_NAME_SPLITTER.split(praeparat)[0].strip().lower()\n",
    "    if len(name) < 4:\n",
    "        return praeparat\n",
    "    return name\n",
    "\n",
    "\n",
    "df_all['praeparat'] = df_all[u'Präparatname'].apply(clean_praeparat)\n",
    "\n",
    "print('Original Präparatname Number of Groups', len(df_all[u'Präparatname'].value_counts()))\n",
    "print('Cleaned Präparatname Number of Groups', len(df_all['praeparat'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for name in num_cols:\n",
    "    new_name = 'num_%s' % name\n",
    "    df_all[new_name] = df_all[name].copy()\n",
    "    df_all[new_name] = df_all[new_name].apply(str)\n",
    "    \n",
    "    if name not in float_cols:\n",
    "        df_all[new_name] = (df_all[new_name]\n",
    "                        .str.replace('(geplante Anzahl *:?|ca\\.|max\\.|geplant *:)', '', flags=re.I)\n",
    "                        .str.strip()\n",
    "                        .str.replace(r'[ ,\\.]', '')\n",
    "        )\n",
    "    df_all[new_name] = (df_all[new_name]\n",
    "                    .str.replace('^\\d+-(\\d+)$', '\\\\1')\n",
    "    )\n",
    "    if name not in float_cols:\n",
    "        df_all[new_name] = (df_all[new_name]\n",
    "            .str.replace(r'^(\\d+).*', '\\\\1', flags=re.I)\n",
    "        )\n",
    "    df_all[new_name] = pd.to_numeric(df_all[new_name], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if cleaning kind of worked\n",
    "df_all[df_all['Patienten geplant'].str.contains(' ').fillna(False)][['Patienten geplant', 'num_Patienten geplant']].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Here's some exploratory analysis around the dataset.\n",
    "\n",
    "First step is to group the single update and final notices into observational studies (AWB).\n",
    "We define the identification of one AWB to be the combination of its drug name, its registration date and its start date.\n",
    "\n",
    "Per group of notices we find maxmimal numeric values for certain key figures and take the most prominent or last value for other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_value(series):\n",
    "    vc = series.value_counts()\n",
    "    if len(vc) == 0:\n",
    "        lvi = series.last_valid_index()\n",
    "        if lvi is None:\n",
    "            return None\n",
    "        return series[lvi]\n",
    "    return vc.idxmax()\n",
    "\n",
    "def get_awbs(groups):\n",
    "\n",
    "    for key, rows in groups:\n",
    "        # Use maximum number across columns and rows for one AWB\n",
    "        patient_count = rows[['num_Patienten beobachtet', 'num_Patienten geplant']].max().max()\n",
    "        doc_count = rows[['num_beobachtende Ärzte', 'num_gemeldete Ärzte']].max().max()\n",
    "        fee_per_patient = rows[[u'num_Aufwandsentschädigung pro Patient']].max().max()\n",
    "        \n",
    "        yield pd.DataFrame([{\n",
    "                'praeparat': key[0],\n",
    "                'Präparatname': get_best_value(rows['Präparatname']),\n",
    "                'dt_DatumErstanzeige': key[1],\n",
    "                'dt_Start': key[2],\n",
    "                'patient_count': patient_count,\n",
    "                'doc_count': doc_count,\n",
    "                'fee_per_patient': fee_per_patient,\n",
    "                'calculated_total_fee': fee_per_patient * patient_count,\n",
    "                'fee_comment': get_best_value(rows['Aufwandsentschädigung Kommentar']),\n",
    "                'final_total_fee': rows['Aufwandsentschädigung gesamt'].max(),\n",
    "                # Use most used values across AWB rows\n",
    "                'Auftraggeber': get_best_value(rows['Auftraggeber']),\n",
    "                'Firma': get_best_value(rows['Firma']),\n",
    "                'Wirkstoff': get_best_value(rows['Wirkstoff']),\n",
    "                'dt_DatumEnde': get_best_value(rows['dt_DatumEnde']),\n",
    "            }])\n",
    "\n",
    "\n",
    "awb_grouper = ['praeparat', 'dt_DatumErstanzeige', 'dt_DatumStart']\n",
    "groups = df_all.sort_values(['dt_DatumEingang']).groupby(awb_grouper)\n",
    "df_awb = pd.concat(get_awbs(groups))\n",
    "df_awb = df_awb.reset_index(drop=True)\n",
    "df_awb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of extracted AWBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_awb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numbers of patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_awb['patient_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_awb['patient_count'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numbers of doctors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_awb['doc_count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_awb['doc_count'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fee per Patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_awb['fee_per_patient'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_awb['final_total_fee'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many AWBs over the years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awbs_per_year = df_awb.groupby(df_awb.dt_DatumErstanzeige.dt.year).size()\n",
    "\n",
    "# Drop stupid values\n",
    "awbs_per_year = awbs_per_year.drop([1900, 1905])\n",
    "awbs_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awbs_per_year.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many patients were in the studies over the years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "patients_per_year = df_awb.groupby(df_awb.dt_Start.dt.year)['patient_count'].sum()\n",
    "patients_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_per_year.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many doctors participated over the years?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctors_per_year = df_awb.groupby(df_awb.dt_Start.dt.year)['doc_count'].sum()\n",
    "doctors_per_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doctors_per_year.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "awbv = ['Auftraggeber', 'Firma', 'Präparatname', 'doc_count', 'patient_count', 'final_total_fee', 'fee_per_patient',\n",
    "        'fee_comment', 'calculated_total_fee', 'praeparat', 'Wirkstoff', 'dt_DatumEnde', 'dt_DatumErstanzeige',\n",
    "        'dt_Start']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highest patient count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_awb.sort_values('patient_count', ascending=False).head(10)[awbv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highest fee per patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_awb.sort_values('fee_per_patient', ascending=False).head(10)[awbv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highest calculated total fee (fee per patient times number of patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_awb.sort_values('calculated_total_fee', ascending=False).head(10)[awbv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highest total final costs per AWB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_awb.sort_values('final_total_fee', ascending=False).head(10)[awbv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MabThera AWB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = ['dt_DatumEingang', 'Präparatname', 'Auftraggeber', 'Patienten beobachtet', 'Patienten geplant',\n",
    "     'Aufwandsentschädigung pro Patient', 'Aufwandsentschädigung gesamt in €', 'row_type', 'year', 'row_number']\n",
    "df_all[(df_all['Präparatname'] == 'MabThera') & (df_all['dt_DatumErstanzeige'].dt.year == 2009) & (df_all['dt_DatumErstanzeige'].dt.month == 5)][v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_awb[df_awb['Präparatname'] == 'MabThera'][awbv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference between calculated total fee and final total fee\n",
    "\n",
    "Top 10 where final total is higher than calculated total costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_awb['final_calculated_diff'] = df_awb['calculated_total_fee'] - df_awb['final_total_fee']\n",
    "df_awb.sort_values('final_calculated_diff').head(10)[['final_calculated_diff'] + awbv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 where final total is lower than calculated total costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_awb.sort_values('final_calculated_diff', ascending=False).head(10)[['final_calculated_diff'] + awbv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rough Top 10 final total fee by Firma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_awb.groupby('Firma')['final_total_fee'].sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of fee comments\n",
    "\n",
    "\"Patient independent payments\" and other interesting bits can be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 120)\n",
    "v = ['Präparatname', 'Auftraggeber', 'Patienten geplant', 'Aufwandsentschädigung pro Patient', 'Aufwandsentschädigung gesamt in €']\n",
    "abschluesse_df[abschluesse_df['Aufwandsentschädigung gesamt in €'].str.contains('unabh').fillna(False)][v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[df_all['Typ'] == 'Nahrungsergänzungsmittel'][v]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
